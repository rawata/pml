{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning  - Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['bar', 'foo', 'hello', 'lottery', 'prize', 'winner', 'world']\n",
      "X_train:\n",
      "====\n",
      "[[0 0 2 0 0 0 1]\n",
      " [0 0 1 0 0 0 2]\n",
      " [0 0 2 0 0 0 2]\n",
      " [1 2 0 0 0 0 0]\n",
      " [2 1 0 0 0 0 0]\n",
      " [2 2 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 0]\n",
      " [0 0 0 1 1 0 0]\n",
      " [0 0 0 3 1 1 0]]\n",
      "====\n",
      "\n",
      "X_test:\n",
      "====\n",
      "[[1 1 0 0 0 0 0]\n",
      " [0 0 1 1 1 0 0]]\n",
      "====\n",
      "\n",
      "Indices of nearest documents:\n",
      "====\n",
      "0\n",
      "====\n",
      "\n",
      "Distances of nearest documents:\n",
      "====\n",
      "0\n",
      "====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Building a dataset of documents\n",
    "'''\n",
    "\n",
    "'''\n",
    "    Training docs\n",
    "'''\n",
    "doc0 = \"hello hello world \"\n",
    "doc1 = \"hello world world\"\n",
    "doc2 = \"hello world hello world\"\n",
    "doc3 = \"foo foo bar \"\n",
    "doc4 = \"foo bar bar\"\n",
    "doc5 = \"foo bar foo bar\"\n",
    "doc6 = \"lottery prize winner\"\n",
    "doc7 = \"lottery prize\"\n",
    "doc8 = \"lottery lottery lottery prize winner\"\n",
    "docs_train = [doc0, doc1, doc2, doc3, doc4, doc5, doc6, doc7, doc8]\n",
    "\n",
    "'''\n",
    "    Test docs\n",
    "'''\n",
    "doct0 = \"foo bar\"\n",
    "doct1 = \"lottery prize hello\"\n",
    "docs_test = [doct0, doct1]\n",
    "\n",
    "\n",
    "'''\n",
    "    Converting documents to feature vectors\n",
    "'''\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(docs_train).toarray()\n",
    "features = vectorizer.get_feature_names()\n",
    "print(f'Features: {features}')\n",
    "print(f'X_train:\\n====\\n{X_train}\\n====\\n')\n",
    "X_test = vectorizer.transform(docs_test).toarray()\n",
    "print(f'X_test:\\n====\\n{X_test}\\n====\\n')\n",
    "\n",
    "'''\n",
    "Choosing the model\n",
    "'''\n",
    "model = NearestNeighbors(n_neighbors=3, algorithm='brute')\n",
    "\n",
    "'''\n",
    "    Train the model\n",
    "'''\n",
    "#TBD Train the model\n",
    "\n",
    "'''\n",
    "    Test the model, by getting  k=3 most similar documents, and their distances to the ones in test docs \n",
    "'''\n",
    "#TBD Test the model\n",
    "\n",
    "indices, distances = (0,0)\n",
    "\n",
    "print(f'Indices of nearest documents:\\n====\\n{indices}\\n====\\n')\n",
    "print(f'Distances of nearest documents:\\n====\\n{distances}\\n====\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning  - Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud Transaction Prediction (-1 means anomaly/outlier i.e fraud):\n",
      "====\n",
      "[]\n",
      "====\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "'''\n",
    "features = [\"amount_category\", \"merchant_web_mobile\", \"dow\",  \"hour\" ]\n",
    "feature description\n",
    "    amount_category       0 if amount < £100\n",
    "                          1 if  £100 <= amount < £500)\n",
    "                          2 if  £500 <= amount\n",
    "\n",
    "    merchant_web_mobile   0 if  transaction done in shop\n",
    "                          1 if  transaction done through web\n",
    "                          2 if  transaction done through mobile    \n",
    "    \n",
    "    dow                   transaction day of week (1-7)\n",
    "    hour                  transaction hour (1-24)\n",
    "'''\n",
    "def normal_txn_hour():\n",
    "    return random.randint(9,18)\n",
    "def normal_txn_dow():\n",
    "    return random.randint(1,5)\n",
    "\n",
    "'''\n",
    "Building a hypothetical dataset of normal transactions\n",
    "'''\n",
    "N = 1000\n",
    "X_train = [[0, 0, normal_txn_dow(), normal_txn_hour()] for i in range(N)]\n",
    "# print(*X_train, sep = \"\\n\")\n",
    "\n",
    "'''\n",
    "Building a hypothetical test dataset: some fraud transactions and some normal\n",
    "'''\n",
    "X_test = [\n",
    "    [1,2,6,23],\n",
    "    [1,2,6,23],\n",
    "    [0,0,2,11],\n",
    "]\n",
    "\n",
    "'''\n",
    "Choosing a model\n",
    "'''\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "model = EllipticEnvelope()\n",
    "\n",
    "'''\n",
    "    Train the model so that it understand whats normal transaction\n",
    "'''\n",
    "\n",
    "#TBD\n",
    "\n",
    "\n",
    "'''\n",
    "   Use the trained model to predict if the given transactions are fraudlent or not\n",
    "'''\n",
    "\n",
    "#TBD \n",
    "predictions = []\n",
    "\n",
    "print(f'Fraud Transaction Prediction (-1 means anomaly/outlier i.e fraud):\\n====\\n{predictions}\\n====\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
