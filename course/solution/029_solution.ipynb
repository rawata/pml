{
 "cells": [
  {
   "source": [
    "<img src=\"../../img/mldlc2.png\" width=\"900\">"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## KFold and StratifiedKFold train test split"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import collections\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [4, 5], [4, 4], [5, 6], [6, 7], [8, 9], [9, 10], [11, 12]])\n",
    "Y = np.array([0, 0, 0, 1, 1, 1, 2, 2, 2])\n",
    "\n",
    "# 3 Fold split\n",
    "print(\"====K-Fold Split====\")\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=101)\n",
    "for train_indices, test_indices in kf.split(X, Y):\n",
    "   print(\"train indices:\", train_indices, \"test indices:\", test_indices)\n",
    "   X_train, X_test = X[train_indices], X[test_indices]\n",
    "   Y_train, Y_test = Y[train_indices], Y[test_indices]\n",
    "\n",
    "\n",
    "#StratifiedKFold distributes the target labels within fold in same ratio in which they appear in main dataset\n",
    "\n",
    "# TBD: Use StratifiedKFold to split X and Y into 3 fold train test set and verify that all the three target labels (0, 1, 2) are present in each fold\n",
    "#StratifiedKFold distributes the target labels within fold in same ratio in which they appear in main dataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "print(\"\\n====Stratified K-Fold Split====\")\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "for train_indices, test_indices in skf.split(X, Y):\n",
    "    print(\"train indices:\", train_indices, \"test indices:\", test_indices)\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    Y_train, Y_test = Y[train_indices], Y[test_indices]\n",
    "    train_label_ratio = { k:v/len(Y_train) for (k,v) in collections.Counter(Y_train).items() }\n",
    "    print(f'Label ratio in train = {train_label_ratio}')\n",
    "    test_label_ratio = { k:v/len(Y_test) for (k,v) in collections.Counter(Y_test).items() }\n",
    "    print(f'Label ratio in test = {test_label_ratio}')\n",
    "    print(train_label_ratio == test_label_ratio)\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## GridSearch CV (Search for a best set of hyperparams for a given model)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##Load Boston housing dataset\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, Y = load_boston(return_X_y=True)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=101)\n",
    "\n",
    "model = KNeighborsRegressor(n_neighbors=3)\n",
    "model.fit(X_train, Y_train)\n",
    "Y_hat = model.predict(X_test)\n",
    "\n",
    "#Some baseline performance\n",
    "print(mean_squared_error(Y_test, Y_hat))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def grid_summary(grid_result):\n",
    "    print(f\"\\nBest: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(f\"{mean},{stdev} with: {param}\")\n",
    "\n",
    "## TBD Using GridSearchCV check which value of param n_neighbors [2,3,4,5,6,7,8] gives the best results\n",
    "# This is a subset of below problem, its paramgrid has one less param to worry about.\n",
    "n_neighbors = [2,3,4,5,6,7,8]\n",
    "param_grid = { 'n_neighbors':n_neighbors}\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv = 3, scoring = 'neg_mean_squared_error' )\n",
    "res = grid.fit(X_train, Y_train)\n",
    "grid_summary(res)\n",
    "\n",
    "## TBD Using GridSearchCV check which value of param combination n_neighbors [2,3,4,5,6,7,8], p [1, 2] gives the best result\n",
    "n_neighbors = [2,3,4,5,6,7,8]\n",
    "p = [1,2]\n",
    "param_grid = { 'n_neighbors':n_neighbors, 'p': p }\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv = 3, scoring = 'neg_mean_squared_error' )\n",
    "res = grid.fit(X_train, Y_train)\n",
    "grid_summary(res)\n",
    "\n",
    "Y_hat = grid.predict(X_test)\n",
    "print(mean_squared_error(Y_test, Y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Gridsearch across different algorithms\n",
    "\n",
    "## TBD Create a ML pipeline that selects the best model-param combination among given set of madels and params\n",
    "* LinearRegression, No params\n",
    "* KNeighborsRegressor, params: {n_neighbors : [4,5,6], p: [1,2]}\n",
    "* XGBoost, params : {n_estimators: [100,200,300], max_depth: [3,4,5,6,7,8], subsample: [0.9, 1.0, 1.1] }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import  Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "pipe  = Pipeline([('model', LinearRegression())])\n",
    "param_grid = [\n",
    "              {'model' : [LinearRegression()]},\n",
    "              {'model' : [KNeighborsRegressor()], 'model__n_neighbors': [2,3,4], 'model__p': [1,2]},\n",
    "              {'model' : [GradientBoostingRegressor()], 'model__n_estimators': [50,100,200], 'model__max_depth': [2,3,4,5,6,7] }\n",
    "            ]\n",
    "\n",
    "grid = GridSearchCV(estimator=pipe, param_grid=param_grid, cv=3, scoring = 'neg_mean_squared_error')\n",
    "\n",
    "res = grid.fit(X_train, Y_train)\n",
    "grid_summary(res)\n",
    "\n",
    "Y_hat = grid.predict(X_test)\n",
    "print(mean_squared_error(Y_test, Y_hat))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}