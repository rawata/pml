{
 "cells": [
  {
   "source": [
    "## Convolutional Neural Networks (CNN)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## TBD Doing better on Fashion MNIST dataset using CNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Normalized features\n",
    "X_train = X_train.reshape(60000,28,28,1)/255.0\n",
    "X_test = X_test.reshape(10000,28,28,1)/255.0\n",
    "\n",
    "# Encode Y as binary class vector\n",
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "\n",
    "# TBD: Use following architecture to classify fashion MNIST dataset\n",
    "# activation function is relu for all layers except last where its softmax\n",
    "# 1 Convolutional Layer (filters = 64, kernel_size = 4 )\n",
    "# 2 Convolutional Layer (filters = 64, kernel_size = 4)\n",
    "# 3 Max Pooling Layer (size 2)\n",
    "# 4 Convolutional Layer (filters = 128, kernel_size = 3)\n",
    "# 5 Convolutional Layer (filters = 128, kernel_size = 3)\n",
    "# 6 Max Pooling Layer (size 2)\n",
    "# 7 Dense Layer (64 neurons)\n",
    "# 8 Dense Layer (10 neurons, activation = softmax)\n",
    "model = Sequential([\n",
    "    Conv2D(64, 3, activation=\"relu\", padding=\"same\", input_shape=[28, 28, 1]),\n",
    "    Conv2D(64, 4, activation=\"relu\", padding=\"same\"),\n",
    "    MaxPooling2D(2),\n",
    "    Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "    MaxPooling2D(2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation=\"relu\"),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.01, momentum=0.9), metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, batch_size=100, epochs=10, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "source": [
    "## Recurrent Neural Networks(RNNs) "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Sequence Prediction\n",
    "\n",
    "## Simple RNN\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense\n",
    "from keras.optimizers import SGD\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer, StandardScaler\n",
    "\n",
    "def ts2XY(ts, n):\n",
    "    '''\n",
    "    Generates a features and labels from a timeseries sequence\n",
    "    ignores the timestamp, just arranges the sequence\n",
    "    into n features by shifting 1 for each feature\n",
    "    also removes the rows which have NaN due to shifting (first n  rows)\n",
    "    (no error handling for now)\n",
    "    :param ts: univariate timeseries dataframe, with a 'value' column\n",
    "    :param n: number of features\n",
    "    :return: X , Y\n",
    "    '''\n",
    "\n",
    "    X = pd.concat(\n",
    "          [\n",
    "            ts['value'].shift(i).rename(f'feature_{i}')\n",
    "              for i in range(1, n+1)\n",
    "          ], axis = 1)\n",
    "\n",
    "    Y = ts['value'][:].to_frame()\n",
    "    Y = ts['value'][n:].to_frame()\n",
    "    X = X[n:]\n",
    "    return X,Y\n",
    "\n",
    "\n",
    "\n",
    "def evalts(ts, lookback, scaler, metric, test_size=0.25):\n",
    "\n",
    "    if scaler is not None:\n",
    "        ts['value'] = scaler.fit_transform(ts['value'].to_frame())\n",
    "\n",
    "    X,Y = ts2XY(ts, lookback)\n",
    "\n",
    "    assert(len(X) == len(Y) and 0.0 <= test_size <= 1.0 )\n",
    "\n",
    "    f = int(len(X)*test_size)\n",
    "\n",
    "    X_train,X_test,Y_train,Y_test = X[:f],X[f:],Y[:f],Y[f:] #because we want to preserve the order\n",
    "\n",
    "    Y_hat1 = X_test.iloc[:, -1]\n",
    "    print(f\"model1 (last observation) {metric.__name__} = {metric(Y_test, Y_hat1)}\")\n",
    "\n",
    "    Y_hat2 = X_test.mean(axis=1)\n",
    "    print(f\"model2 (mean of lookback observations) {metric.__name__} = {metric(Y_test, Y_hat2)}\")\n",
    "\n",
    "    model3 = LinearRegression()\n",
    "    model3.fit(X_train, Y_train)\n",
    "    Y_hat3 = model3.predict(X_test)\n",
    "    print(f\"model3 (Linear regression) {metric.__name__} = {metric(Y_test, Y_hat3)}\")\n",
    "\n",
    "    model4 = Sequential([\n",
    "      SimpleRNN(1, input_shape=[None, 1])\n",
    "    ])\n",
    "\n",
    "    model4.compile(loss=\"mse\", optimizer=SGD(lr=0.01, momentum=0.9))\n",
    "    X_train_ts = np.array(X_train).reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    model4.fit(X_train_ts, Y_train, epochs=100, verbose=0)\n",
    "    Y_hat4 = model4.predict(np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1))\n",
    "    print(f\"model4 (RNN 1) {metric.__name__} = {metric(Y_test, Y_hat4)}\")\n",
    "\n",
    "    model5 = Sequential([\n",
    "        SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "        SimpleRNN(20, return_sequences=True),\n",
    "        SimpleRNN(1)\n",
    "        # SimpleRNN(20),\n",
    "        # Dense(1, activation='relu')\n",
    "    ])\n",
    "\n",
    "    model5.compile(loss=\"mse\", optimizer=SGD(lr=0.01, momentum=0.9))\n",
    "    model5.fit(X_train_ts, Y_train, epochs=10, verbose=0)\n",
    "    Y_hat5 = model5.predict(np.array(X_test).reshape(X_test.shape[0], X_test.shape[1], 1))\n",
    "    print(f\"model5 (RNN n) {metric.__name__} = {metric(Y_test, Y_hat5)}\")\n",
    "\n",
    "ts = pd.read_csv('https://raw.githubusercontent.com/numenta/NAB/master/data/artificialNoAnomaly/art_daily_no_noise.csv')\n",
    "evalts(ts, 7, MinMaxScaler(), mean_squared_error)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}