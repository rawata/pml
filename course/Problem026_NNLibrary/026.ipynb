{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from numpy.random import seed\n",
    "seed(101)\n"
   ]
  },
  {
   "source": [
    "## sklearn MNIST(8X8) dataset with dense NN using keras (Same as problem 25)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Preparing the digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "X = digits.data\n",
    "\n",
    "# One hot encoding of target (Y)\n",
    "Y = np_utils.to_categorical(digits.target, 10)\n",
    "\n",
    "# Train test split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "# Model Architecture [(64, None), (40, relu), (20, relu), (10, sigmoid)]\n",
    "model = Sequential()\n",
    "model.add(Dense(40, activation='relu', input_shape=(64,)))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "#Model hyperparams. (though architecture also is a hyperparam)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=SGD(lr=0.0075),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "#Training the model\n",
    "model.fit(X_train, Y_train,\n",
    "            batch_size=len(X_train), epochs=3000,\n",
    "            verbose=1, validation_split=0.2)\n",
    "\n",
    "# Testing the model\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "\n",
    "print(\"Test loss:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "source": [
    "## TBD: Use same Neural Network as above on standard MNIST dataset (28X28 = 784 pixels) "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "from keras.datasets import mnist\n",
    "#Data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(60000, 28*28)\n",
    "X_test = X_test.reshape(10000, 28*28)\n",
    "\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# Encode Y as binary class vector\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "# TBD: Build a 3 layer [(784, None), (40, relu), (20, relu), (10, sigmoid)] Neural Network\n",
    "# using Keras, train it on X_train dataset, and compute accuracy and loss on test dataset.\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "## NN Fashion\n",
    "## TBD: Use above Neural Network on Fashion MNIST  dataset (28X28 = 784 pixels) "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#TBD Explore data (input shape, output shape) Fashion MNIST is a drop in replacement \n",
    "# for MNIST so shapes should be same. \n",
    "\n",
    "#TBD View the images (clothing types) and their labels \n",
    "\n",
    "#TBD: Build a 3 layer [(784, None), (40, relu), (20, relu), (10, sigmoid)] Neural Network\n",
    "# using Keras, train it on X_train dataset, and compute accuracy and loss on test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('pml': venv)",
   "metadata": {
    "interpreter": {
     "hash": "a4c9474aacc61cf72d0f1c29f4a339e5d6b2171c287541cfd684cf058783219b"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}